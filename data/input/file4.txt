атрицями Гессе завдяки 
застосуванню більш евристичної оцінки важливості параметрів. Також було 
запропоновано використання ітеративного прунінгу, під час якого 
проріджування параметрів моделі виконувалося кілька разів у процесі 
навчання. Таким чином, після кожної ітерації прунінгу модель донавчалася, 
що дозволяло ще більше зменшувати її розмір при збереженні точності. 
Важливим внеском у розвиток прунінгу стало дослідження "Гіпотеза 
лотерейного квитка". Це дослідження стверджує, що в глибоких моделях з 
високою щільністю існують підмережі, які здатні досягати аналогічної 
102 
продуктивності при повторному навчанні за умови відповідної ініціалізації 
початкових параметрів [115, 116]. 
Також було досліджено підходи до прунінгу, за яких видалення 
параметрів відбувається структуровано. У цьому випадку замість окремих 
зв’язків можуть видалятися цілі нейрони, фільтри або канали. Перевагою 
застосування структурованого прунінгу є не лише зменшення кількості 
параметрів, але й ефективне скорочення використання пам’яті та 
пришвидшення роботи моделі на апаратних засобах, оптимізованих для 
роботи з густими матрицями [117]. Порівнюючи структурований і 
неструктурований прунінг, важливо враховувати низку ключових факторів. 
Перш за все, варто звернути увагу на те, що хоча неструктурований прунінг не 
змінює архітектуру, а лише обнуляє певні параметри, це не завжди призводить 
до пришвидшення моделі. Це зумовлено необхідністю застосування 
спеціальних алгоритмів для обчислень розріджених матриць, проте такі 
обчислення зазвичай недостатньо оптимізовані в стандартному апаратному 
забезпеченні. Це може призвести не лише до відсутності пришвидшення 
моделі, а й до її сповільнення. На противагу цьому, структурований прунінг 
змінює топологію моделі, що дозволяє використовувати оптимізовану модель 
без зайвих обчислень, а також робить її ефективною на сучасних графічних 
процесорах та спеціалізованих апаратних прискорювачах, оскільки після 
структурованого прунінгу модель залишається компактною. Іншим важливим 
фактором є можливість мінімізувати або повністю уникнути донавчання 
моделі після неструктурованого прунінгу, тоді як після структурованого 
прунінгу донавчання є необхідним для відновлення точності моделі [118]. 
Також можна виділити напівструктурований прунінг, який дозволяє знайти 
компроміс між структурованим та неструктурованим прунінгом, як це 
продемонстровано на рисунку 3.1. 
103 
Рисунок 3.1 - Порівняння різних шаблонів прунінгу 
Також було розроблено адаптивні методи прунінгу, такі як Dynamic 
Network Surgery (DNS). Цей метод прунінгу застосовується безпосередньо під 
час навчання, аналізуючи важливість вагових коефіцієнтів у процесі 
тренування. Далі, на основі порогових значень, визначаються ваги, які 
потрібно видалити. Проте, на відміну від класичних підходів до прунінгу, 
метод DNS пропонує механізм відновлення ваг на основі аналізу градієнтів. 
Під час тренування метод DNS аналізує градієнти для кожної ваги нейронної 
мережі, і якщо обнулена вага отримує високий градієнт, вона повертається до 
моделі. Завдяки цьому метод DNS дозволяє адаптивно змінювати структуру 
нейронної мережі, мінімізуючи втрати точності [119]. 
Іншим важливим досягненням стало розроблення методів прунінгу на 
основі чутливості, таких як Single-shot Network Pruning based on Connection 
Sensitivity (SNIP). Головною особливістю методу SNIP є його використання 
перед навчанням, на відміну від інших методів прунінгу, які інтегруються в 
процес навчання або застосовуються після нього. Алгоритм роботи SNIP 
полягає в тому, що береться модель нейронної мережі, ініціалізована 
випадковими вагами, а також вибирається невелика частина датасету, після 
104 
чого виконується прохід через нейронну мережу. На основі отриманого 
результату визначається вплив кожної ваги на функцію втрат. Після оцінки 
важливості ваг виконується прунінг, а параметри, що залишилися, тренуються 
стандартним підходом. Хоча при застосуванні цього підходу модель може 
мати обмежений простір для адаптації, а видалення великої кількості ваг може 
призвести до зниження точності, цей метод усуває потребу в додатковому 
навчанні, дозволяє контролювати втрату точності та значно пришвидшує не 
лише швидкодію моделі, а й сам процес навчання [120]. 
Аналізуючи існуючі підходи до прунінгу, можна чітко простежити 
тенденцію, яка вказує на необхідність пошуку компромісу між точністю 
моделей та їх швидкодією. При цьому дослідження методів прунінгу глибоких 
нейронних мереж дало поштовх до вивчення роботи розріджених мереж, 
динаміки навчання нейронних мереж та їх узагальнювальної здатності. 
3.1.3. Прунінг архітектур трансформер 
Застосування архітектур трансформерів дозволяє значно підвищити 
точність розпізнавання у задачах, які потребують визначення просторових чи 
часових залежностей. Проте використання таких моделей вимагає значних 
обчислювальних ресурсів та пам’яті. Ці обмеження зробили підходи до 
компресії моделей надзвичайно важливими для підготовки моделей до 
використання на пристроях з обмеженими ресурсами, а також у задачах, що 
потребують високої швидкості виконання. 
Проте, на відміну від звичайних глибоких нейронних мереж, архітектури 
трансформерів мають унікальні виклики, пов’язані з оптимізацією механізмів 
багатоголової самоуваги та позиційно-залежних згорткових шарів. 
Дослідження механізму уваги показали, що збільшення кількості голів уваги 
дає мінімальний внесок у загальну точність моделі. При цьому було 
встановлено, що значну частину голів уваги можна видаляти, зберігаючи 
105 
високу точність моделі, що свідчить про надмірну кількість параметрів у 
шарах уваги [121]. Інше дослідження представило емпіричні докази 
ефективності скорочення кількості голів уваги у моделях трансформерів зі 
збереженням високої точності, що підтвердило ефективність використання 
методів прунінгу для голів уваги в трансформерних моделях [122]. 
Останні дослідження у сфері прунінгу запропонували, окрім прунінгу 
голів уваги, також застосовувати динамічні та структуровані методи прунінгу. 
Одним із методів динамічного прунінгу став Movement Pruning, у якому 
запропоновано використання траєкторії оновлення ваг моделі під час 
донавчання для ідентифікації параметрів, що роблять найменший внесок у 
результати моделі. У цьому підході відбувається адаптація схеми 
розрідженості матриць під час навчання, що дозволяє моделі ефективно 
зберігати здатність до точного представлення інформації. Цей підхід було 
успішно протестовано на попередньо натренованих моделях, таких як BERT, і 
в результаті його застосування для прунінгу вдалося зменшити кількість 
параметрів більш ніж на 50% при збереженні точності моделі відповідно до 
метрик, таких як GLUE [123]. Також важливо зазначити, що емпіричний аналіз 
впливу методів прунінгу на моделі трансформерів показав не лише зменшення 
розміру моделі, а й зміну її внутрішніх представлень про дані. Це пояснюється 
тим, що після донавчання решта голів уваги починають перерозподіляти свої 
функції, як показано на рисунку 3.2. 
106 
Рисунок 3.2 - Перерозподілення функцій голів уваги при застосуванні 
різної сили прунінгу 
Аналізуючи таку реорганізацію даних, стає очевидним її вплив на 
здатність моделі до інтерпретованості та стійкості. На основі цього можна 
зробити висновок, що зі збільшенням кількості параметрів, які видаляються 
під час прунінгу, швидкість роботи моделі зростає, а використання пам’яті 
значно зменшується. Проте виникає потреба в детальному аналізі 
продуктивності та надійності моделі під час розв’язання різних задач. 
Також було проведено дослідження прунінгу на рівні шарів для моделей 
трансформерів. У цьому випадку структурований прунінг дає можливість 
видаляти цілі компоненти, такі як голови уваги чи шари, що, порівняно з 
неструктурованими методами прунінгу, дозволяє формувати регулярні 
шаблони розрідженості. Це, своєю чергою, дає змогу таким моделям після 
прунінгу значно ефективніше використовувати апаратне прискорення. 
Важливо враховувати, що, оскільки застосування структурованих підходів 
107 
тісно пов’язане з апаратною архітектурою, оптимальний результат можна 
досягти за умови узгодження схеми розрідженості матриць з 
обчислювальними можливостями цільової платформи для використання 
моделі. У результаті аналізу було встановлено, що застосування прунінгу на 
рівні шарів до архітектури трансформерів потребує особливої уваги. Це 
зумовлено ієрархічною структурою трансформерів, у якій різні шари кодують 
різні рівні синтаксичної та семантичної інформації. Емпіричні дослідження 
показали, що видалення середніх шарів моделі дає змогу підвищити 
продуктивність за незначної втрати точності, тоді як видалення шарів на 
початку або в кінці моделі призводить до значної втрати точності, що може 
стати критичним для використання цього підходу. Ця особливість підкреслює 
важливість розробки правильної стратегії прунінгу з урахуванням структури 
моделей архітектури трансформерів. 
3.1.4. Вимоги до програмного забезпечення та обчислювальних 
ресурсів 
Для 
розуміння 
обчислювальних вимог моделей архітектури 
трансформер необхідне детальне вивчення основних арифметичних операцій, 
апаратного забезпечення, яке їх виконує, та існуючих стратегій, що активно 
використовуються для зменшення обчислювального навантаження на 
систему. 
Основною одиницею обчислень у чисельних алгоритмах є операції з 
рухомою комою (FLOP). При застосуванні цієї одиниці до нейронних мереж, 
зокрема трансформерів, кількість FLOP відображає загальну кількість 
арифметичних операцій, які виконує модель під час прямого проходження 
даних через неї. Основними операціями для нейронних мереж є додавання та 
множення матриць. Переважаючими є операції множення матриць, які 
застосовуються в механізмі самоуваги та повнозв’язних шарах і домінують за 
108 
кількістю FLOP. Розрахунок FLOP дозволяє виконувати апаратну діагностику 
для оцінки теоретичного навантаження під час роботи моделі. 
Підрахунок FLOP для моделей архітектури трансформерів має дуже 
важливе значення, оскільки дозволяє дослідникам оцінити потенційні вимоги 
до обчислювальних ресурсів та поведінку моделі під час масштабування 
відповідно до апаратного забезпечення. Ця метрика дає змогу уніфіковано 
порівнювати моделі та допомагає приймати рішення як під час проєктування 
системи та моделі, так і в процесі її оптимізації. Проте важливо зауважити, що 
хоча вимірювання FLOP забезпечує абстрактне розуміння складності моделі, 
воно не враховує нюансів програмного забезпечення. 
Розглядаючи сучасні моделі трансформерів, такі як BERT, GPT та 
Transformer-XL, можна побачити, що їх широке використання стало 
можливим не лише завдяки високій точності, яка значно перевершує точність 
інших архітектур, але й завдяки їх здатності ефективно використовувати 
паралельні обчислення. Оскільки архітектура трансформерів базується на 
використанні багатоголової самоуваги та позиційно-залежних шарів, це 
формує обчислювальні схеми, які складаються з щільних множень матриць 
[124-126]. Використання сучасних центральних та графічних процесорів, які 
мають спеціалізовані апаратні прискорювачі, такі як NVIDIA Tensor Cores та 
векторизовані інструкції AVX-512, дає змогу застосовувати надзвичайно 
оптимізовані операції для множення щільних матриць. Це дозволяє ефективно 
працювати з алгоритмічною структурою моделей архітектури трансформерів, 
використовуючи можливості сучасних апаратних прискорювачів [127, 128]. 
Моделі архітектури трансформер мають вбудований високий рівень 
паралелізму, що дозволяє ефективно оброблювати цілі послідовності 
одночасно, уникаючи вузьких місць у системі, які можуть значно 
уповільнювати розрахунки. На відміну від них, рекурентні нейронні мережі 
мають обмежений рівень паралелізму, що робить їх менш ефективними для 
великомасштабних обчислень. Ця перевага стає ще більш вираженою при 
109 
використанні оптимізованих бібліотек, які пришвидшують операції лінійної 
алгебри, таких як cuBLAS для графічного процесора та Math Kernel Library 
(MKL) для центрального процесора. Також застосування сучасних апаратних 
прискорювачів дозволяє ефективно виконувати великомасштабні операції з 
плаваючою комою, що є важливим фактором при роботі з моделями 
архітектури трансформерів, які містять велику кількість параметрів. Таким 
чином, висока продуктивність моделей архітектури трансформерів 
досягається не лише завдяки алгоритмічному дизайну, а й завдяки розвитку 
апаратного забезпечення, яке адаптується до викликів, пов’язаних із 
розрахунками математичних операцій для щільних матриць [129,130]. 
Важливим фактором при аналізі ефективності виконання певної 
кількості FLOP є врахування типу процесора, на якому проходитимуть 
розрахунки. Центральний процесор (CPU) має невелику кількість потужних 
ядер, які оптимізовані для роботи з різними типами даних та характеризуються 
низькою затримкою при виконанні операцій. Особливістю центральних 
процесорів є наявність складної логіки керування та висока тактова частота, 
завдяки чому вони можуть швидко виконувати задачі різних типів. Спеціальні 
інструкції для роботи з векторними наборами даних, такі як AVX-512, дають 
змогу процесорам паралельно обробляти дані розміром до 512 біт, проте 
загальна кількість ядер для обробки інформації залишається обмеженою. 
Унаслідок цього, незважаючи на можливість центральних процесорів 
демонструвати високу швидкість FLOP на окреме ядро за оптимальних умов, 
їхній рівень паралелізму обмежений через архітектурні особливості CPU. 
На 
противагу центральним процесорам, графічні процесори 
складаються з тисяч простіших ядер, що робить їх більш ефективними при 
застосуванні масового паралелізму. Особливої ефективності графічні 
процесори досягають під час розв’язання задач, що потребують обробки 
однорідних, але водночас інтенсивних обчислень, що є характерним для 
моделей архітектури трансформерів. Також графічні процесори можуть 
110 
містити спеціалізовані блоки, такі як NVIDIA Tensor Cores, які, в свою чергу, 
розширюють їхні можливості та дозволяють виконувати математичні операції 
змішаної точності при дуже високій пропускній здатності. Виходячи з 
особливостей центральних та графічних процесорів, навіть за однакової 
кількості FLOP графічні процесори зазвичай демонструють значно більшу 
ефективність, генеруючи більше результатів за секунду порівняно з 
центральними процесорами. Таким чином, можна зробити висновок, що хоча 
метрика FLOP є незмінним показником навантаження на систему, 
продуктивність моделі значною мірою залежить від можливостей апаратного 
забезпечення, зокрема від рівня паралелізму та ефективності арифметичних 
обчислень. 
3.2. Алгоритм прунінгу  
Використання апаратного забезпечення з високим рівнем паралелізму, 
такого як графічні процесори, дозволяє значно підвищити ефективність 
роботи моделей архітектури трансформерів. Проте розмір таких моделей все 
одно вимагає надзвичайно великої кількості FLOP, яка зазвичай вимірюється 
в мільярдах. Унаслідок цього використання таких моделей призводить до 
значних обчислювальних та енергетичних витрат. Однією з ефективних 
стратегій для суттєвого зменшення обчислювальних та енергетичних вимог є 
використання методів прунінгу, які дають змогу видаляти параметри моделі, 
що найменше впливають на кінцевий результат, мінімізуючи втрату точності. 
Принцип роботи методу прунінгу полягає у виявленні та подальшому 
видаленні ваг, нейронів чи цілих голів уваги, які є найменш важливими. Після 
застосування методів прунінгу кількість FLOP моделі зменшується, оскільки 
для розрахунку результатів під час прямого проходу зменшується кількість 
арифметичних операцій. Внаслідок зменшення кількості FLOP також 
скорочується час виконання моделі та енергоспоживання, що особливо 
111 
важливо для задач, які потребують високої швидкодії, або в середовищах із 
обмеженими ресурсами, таких як периферійні пристрої. 
Проте важливо зазначити, що архітектура моделей трансформерів 
переважно складається з множення щільних матриць у багатоголових шарах 
самоуваги та повнозв’язних шарах. Тому після застосування методів прунінгу 
до моделей архітектури трансформерів, попри теоретичне зменшення 
кількості FLOP, практична зміна швидкодії моделі залежатиме від типу 
розрідженості, яка утворюється після застосування прунінгу. При застосуванні 
неструктурованого прунінгу модель стає нерегулярною, унаслідок чого, 
незважаючи на зменшення кількості FLOP, ефективність її роботи на 
стандартних графічних та центральних процесорах залишається незмінною 
через відсутність підтримки операцій для роботи з розрідженими матрицями. 
При використанні методів структурованого прунінгу блоки формують 
регулярні шаблони, що, своєю чергою, дає змогу краще адаптувати такі моделі 
для використання ефективних операцій з цільними матрицями та їх аналізу за 
допомогою спеціалізованих розріджених ядер. 
Можливим підходом до оптимізації роботи з обрізаними ваговими 
матрицями є зберігання лише ненульових елементів та їхніх індексів у 
форматах CSR або CSC, що дає змогу зменшити вимоги до пропускної 
здатності пам’яті. Також у випадках, коли структура розрідженості є 
регулярною, з моделі видаляються цілі стовпці з матриць значень, ключів чи 
запитів або цілі голови уваги, що дає можливість обробляти решту цільних 
підматриць за допомогою високооптимізованих методів роботи з матрицями. 
Дослідження розріджених моделей трансформерів, які утворюються внаслідок 
застосування структурованого прунінгу, що дає змогу видаляти цілі голови 
уваги, демонструють здатність моделей архітектури трансформерів значно 
зменшувати обчислювальну складність, зберігаючи початкову точність, яка 
була до застосування методів прунінгу. 
3.2.1. Формати зберігання розріджених матриць 
112 
Одним із найпростіших способів представлення розрідженої матриці є 
використання списку координат. Принцип зберігання даних у списку 
координат полягає у збереженні лише ненульових елементів та відповідних 
індексів рядків і стовпців у трьох окремих масивах. Під час переведення даних 
із розрідженої матриці до списку координат утворюються кортежі з трьох 
елементів, де перші два представляють індекси рядка та стовпця, у яких 
знаходиться значення, а третій елемент містить саме це значення. Цей формат 
зберігання даних добре справляється із задачами побудови матриці чи 
інкрементних оновлень, оскільки дозволяє ефективно вміщувати повторювані 
індекси і не потребує визначення структури заздалегідь. Проте при 
використанні списку координат доводиться виконувати неефективні 
арифметичні операції та операції зрізу, через що застосовують модифіковані 
варіанти цього формату. 
Формат стиснення розріджених рядків (CSR) є покращеною версією 
списку координат, оскільки використовує стиснення індексів рядків. Основна 
відмінність цього методу полягає у збереженні масиву вказівників на початок 
та кінець даних для кожного рядка в масиві ненульових значень, замість 
збереження індексу рядка для кожного ненульового елемента. Окрім 
збереження ненульових значень розрідженої матриці та відповідних індексів 
стовпців, матриця CSR містить додатковий масив вказівників для рядків, 
розмір якого на один більший за кількість рядків, як продемонстровано на 
рисунку 3.3. Застосування цього підходу дозволяє ефективно виділяти рядки 
та швидко виконувати множення матриці на вектор завдяки швидкому доступу 
до всіх ненульових елементів у кожному рядку. Формат зберігання даних CSR 
широко застосовується в бібліотеках, які використовуються для прискорення 
операцій, що обробляють дані по рядках, завдяки використанню 
оптимізованих операцій лінійної алгебри [131]. 
113 
Рисунок 3.3 - Зберігання даних у форматі CSR. 
Альтернативним методом стиснення даних є формат compressed sparse 
column (CSC), який, на відміну від CSR, стискає індекси стовпців. При 
зберіганні даних у форматі CSC ненульові елементи зберігаються по стовпцях, 
а також створюється масив вказівників на стовпці, що позначає початок даних 
у кожному стовпці для масиву значень. Застосування формату CSC є 
ефективним для використання в алгоритмах, які вимагають розбиття даних на 
стовпці, а також в операціях, де доступ до даних відбувається у порядку 
збільшення стовпців. Важливо зауважити, що велика кількість програмних 
засобів, зокрема вбудовані функції MATLAB для роботи з розрідженими 
матрицями, використовують формат CSC для виконання ефективних операцій 
на основі стовпців [117]. 
3.2.2. Напів-структурована розрідженість формату 2:4 
114 
Під час застосування методів прунінгу для оптимізації нейронних мереж 
найбільш ефективним є напівструктурований метод прунінгу 2:4. 
Особливістю методу прунінгу 2:4 є те, що у кожному суміжному блоці з 
чотирьох вагових компонентів два компоненти обнуляються, тоді як два інші 
залишаються без змін. Унаслідок застосування методу прунінгу 2:4 матриці 
набувають фіксованої, регулярної розрідженості, що дає змогу ефективно 
скорочувати кількість обчислень, водночас зберігаючи репрезентативні 
властивості моделі, що є критично важливим для великих нейронних мереж, 
зокрема моделей архітектури трансформерів. 
Метод прунінгу 2:4 ділить матриці вагів на групи по чотири послідовних 
елементи, після чого для кожної групи окремо застосовується прунінг на 
основі магнітуди. Внаслідок цього зберігаються лише два вагові коефіцієнти, 
які мають найбільший вплив на систему, тоді як два інші вагові коефіцієнти 
обнуляються. Такий контрольований прунінг забезпечує фіксовану 
розрідженість матриці на рівні 50% та створює передбачувану і регулярну 
структуру матриці в моделі. З метою оптимізації обчислень після застосування 
прунінгу 2:4 використовується таблиця індексів, яка містить інформацію про 
позиції збережених ваг для кожного блоку, як показано на рисунку 3.4. 
Таблиця індексів дозволяє за допомогою виконання матричних операцій 
швидко зчитувати лише ті ваги, що залишилися після прунінгу, ігноруючи 
обнулені. При цьому сучасні спеціалізовані обчислювальні блоки, такі як 
Tensor Cores, дозволяють використовувати таблицю індексів для ефективного 
виконання розріджених обчислень. За рахунок цього таблиця індексів дає 
змогу при використанні методу прунінгу 2:4 виконувати швидкі обчислення у 
розріджених тензорах та ефективно застосовувати програмні пришвидшувачі 
[132]. 
115 
Рисунок 3.4 - Збереження вагів при застосуванні методу прунінгу 2:4 
Сучасне апаратне забезпечення дозволяє ефективно використовувати 
розрідженість матриць завдяки спеціальним ядрам для множення розріджених 
матриць, оптимізованим для обробки розріджених структур за шаблоном 2:4. 
Теоретично це дає змогу отримати прискорення вдвічі порівняно з 
обчисленням повних матриць, проте на практиці прискорення є дещо меншим 
через витрати часу на завантаження метаданих і запуск спеціалізованих ядер. 
Хоча неструктурований прунінг, який видаляє ваги довільно по всій 
матриці, дозволяє досягати високих рівнів компресії, він створює нерегулярні 
схеми доступу до пам’яті, що не забезпечує ефективного прискорення на 
спеціалізованому апаратному забезпеченні з високим рівнем паралелізації, 
такому як графічні процесори. Завдяки чітко визначеній структурі шаблону 2:4 
з’являється можливість розробляти спеціалізовані ядра для роботи з 
розрідженими матрицями. 
Спеціалізовані ядра для роботи з розрідженими матрицями дозволяють 
зберігати вагову матрицю у компактному вигляді, реєструючи лише ненульові 
значення та набір метаданих про їхні позиції для кожної групи, а також 
116 
виконувати обчислення лише на ненульових елементах матриці. Застосування 
такого структурованого підходу не лише спрощує апаратну реалізацію, а й дає 
змогу зберігати високу точність моделі. Емпіричні дослідження, проведені 
компанією NVIDIA та в межах проєкту Sparse-Llama, продемонстрували 
майже повне відновлення точності після використання методу прунінгу 2:4 
[133]. 
Оскільки основні елементи моделей архітектури трансформерів, такі як 
багатоголова самоувага та повнозв’язні шари, містять щільні матриці, 
застосування методу прунінгу 2:4 для їхньої оптимізації є надзвичайно 
ефективним. Проте, оскільки застосування методу прунінгу змінює 
репрезентативні властивості моделей, це може призвести до зниження 
точності. Тому після використання методу прунінгу 2:4 важливо проводити 
донавчання моделей архітектури трансформерів для компенсації можливої 
втрати точності. Дослідження показують, що застосування методу прунінгу 
2:4 з подальшим донавчанням моделі дозволяє досягти майже ідентичної 
точності порівняно з моделями до застосування методу прунінгу, водночас 
значно зменшуючи використання пам’яті та обчислювальних витрат. 
Після застосування методу прунінгу 2:4 вагові матриці зберігаються у 
стисненому форматі, що містить лише ненульові значення та їхні позиції у 
кожній групі. Під час роботи з такими моделями матриці у стисненому 
форматі передаються до спеціалізованих ядер множення розріджених 
матриць, що використовуються в бібліотеках cuSPARSELt та NVIDIA 
CUTLASS, які пропускають нульові значення, завдяки чому значно 
пришвидшується множення матриць [134, 135]. 
При використанні сучасних бібліотек для навчання глибоких нейронних 
мереж, таких як PyTorch, можна застосовувати спеціальні функції для 
перетворення тензорів ваг у напівструктуровані розріджені представлення. 
Функції, такі як to_sparse_semi_structured у бібліотеці PyTorch, дають змогу 
перетворювати вагові матриці після прунінгу у формат, сумісний із 
117 
спеціалізованими ядрами графічних процесорів для роботи з розрідженими 
матрицями. Інтеграція таких методів значно спрощує використання моделей 
архітектури трансформерів після прунінгу методом 2:4 і зменшує інженерні 
витрати на їх розгортання. 
3.2.3. Алгоритмічне забезпечення оцінки важливості вагів для 
напів-структурованої розрідженості 
Принцип роботи методу прунінгу SNIP полягає у знаходженні 
спеціальної підмножини ваг 𝑊subset , яка є частиною початкового набору ваг 𝑊 
і має мінімальне значення функції втрат 𝐿(𝑊subset) для цієї підмножини. У 
контексті роботи нейронної мережі 𝑊 є множиною всіх ваг моделі, а 𝐿(𝑊) — 
функцією втрат, яку нейронна мережа оптимізує під час навчання.  
Принцип роботи алгоритму складається з кількох кроків, першим з яких 
є ініціалізація ваг нейронної мережі випадковими значеннями та створення 
набору масок для вагових векторів, які приймають значення 1 або 0. Далі 
відбувається процес тренування моделі на частині тренувальних даних, що 
дозволяє визначити градієнти функції втрат для кожної маски 𝑚𝑖 . Розраховані 
градієнти вказують на вплив незначних змін у масках на функцію втрат, що 
дає змогу оцінити важливість кожної ваги, використовуючи формулу: 
 
 𝑖 =∣ ∂𝐿(𝑚𝑖)
 ∂𝑚𝑖
 ∣
 (3.1) 
Важливість кожної ваги 𝑤𝑖, що входить до множини 𝑊, обчислюється 
як абсолютне значення часткової похідної функції втрат відносно відповідних 
масок 𝑚𝑖. Після отримання важливостей ваг вони нормалізуються з метою 
визначення їхньої відносної важливості за формулою: 
 
  = 𝐼𝑖
 118 
 
 
 ̂
 ∑𝑗 𝐼𝑗
 (3.2) 
Після цього нормалізовані показники важливості сортуються за 
зростанням, а найменш значущі ваги, що відповідають заданій частці 𝜌, 
обнуляються. Таким чином формується нова підмножина ваг 𝑊𝑠, яка містить 
лише найбільш значущі параметри: 
 
 𝑠 ={𝑤𝑖 ∈𝒲:𝑠̂𝑖 ≥𝜌}
 (3.3) 
Кількість ваг, що видаляються, визначається параметром 𝜌, значення 
якого може змінюватися від 0, коли прунінг не виконується, до 1, коли 
видаляються всі можливі ваги. Таким чином, параметр 𝜌 визначає відсоткове 
співвідношення ваг, які потрібно видалити, і може бути представлений 
наступною формулою: 
 
  =𝑁pruned
 𝑁total
 (3.4) 
Після застосування методу прунінгу модель навчають, використовуючи 
стандартні підходи. Однак, для забезпечення ефективності цього процесу 
важливо зберігати однакову дисперсію для всіх шарів. Для цього 
використовують ініціалізацію Ксав’є, яка забезпечує оптимальний розподіл 
ваг нейронної мережі та розраховується за такою формулою: 
 
 ∼𝒰(− √6
 √𝑛in +𝑛out
 , √6
 √𝑛in +𝑛out
 )
 (3.5) 
119 
Запропонований алгоритм прунінгу є модифікацією методу прунінгу 
SNIP, яка враховує показники уваги моделей архітектури трансформерів під 
час оцінки важливості ваг. 
На відміну від класичного застосування методу SNIP, який визначав 
розрідженість підмножини ваг 𝑊𝑠, де 𝑊𝑠 ⊆ 𝑊, з метою мінімізації функції 
втрат, новий підхід включає активацію уваги та вектори виходу моделі, що 
формалізуються такою формулою: 
 
 ′ = 𝐿(𝑊)+∑
 𝑗
 𝐴𝑗 +𝑂
 (3.6) 
, де 𝐴𝑗 позначає сумарні виходи для 𝑗-го шару уваги, а 𝑂 представляє суму 
тензора виходів, що, своєю чергою, дає змогу розраховувати важливість ваг за 
розширеною формулою: 
 
 𝑖 =∣ ∂𝐿′(𝑐𝑖)
 ∂𝑐𝑖
 ∣
 (3.7) 
Застосування цієї модифікації дає змогу під час зворотного проходження 
збільшувати значення градієнтів відповідно до чутливості кожної окремої ваги 
у шарах уваги. Враховуючи важливість механізму уваги в моделях архітектури 
трансформерів, включення цих параметрів до критеріїв прунінгу дозволяє 
значно підвищити ефективність запропонованого методу. 
Особливістю оригінального методу прунінгу SNIP є створення 
нерегулярних матриць під час обрізання, що зумовлено неструктурованим 
підходом цього методу. Оскільки в результаті неструктурованого прунінгу 
виникає нерегулярна розрідженість матриць, швидкість обробки таких 
моделей може не збільшуватися або зростати мінімально навіть за умови 
використання сучасних апаратних пришвидшувачів, таких як графічні 
120 
процесори. Це пов’язано з тим, що графічні процесори мають високий рівень 
паралелізації та розроблені для роботи з регулярними шаблонами обчислень. 
Тому для вирішення цієї проблеми було вирішено додати до 
запропонованого методу прунінгу інтеграцію напівструктурованої схеми 
розрідженості 2:4. У цій схемі вагова матриця розбивається на суміжні групи 
по чотири елементи, після чого два елементи, що мають найменший вплив на 
систему, обнуляються, як показано на рисунку 3.5. Однак це накладає 
обмеження на фіксовану розрідженість матриць у розмірі 50%. Водночас 
такий підхід дає змогу проводити ефективні обчислення на спеціалізованому 
апаратному забезпеченні, зокрема на розріджених ядрах у графічних 
процесорах NVIDIA Ampere. 
Рисунок 3.5 - Застосування прунінгу 2:4 
Поєднання модифікованого методу SNIP із застосуванням розрідженості 
матриць 2:4 дає змогу ефективно оптимізувати моделі архітектури 
трансформерів, водночас зберігаючи напівструктурованість матриць. Це, 
121 
своєю чергою, дозволяє ефективно використовувати апаратні пришвидшувачі 
для досягнення значного прискорення не лише під час застосування моделі для 
вирішення прикладних задач, але й під час її навчання без втрати точності. 
3.2.4. Експериментальна оцінка удосконаленого методу оптимізації 
З метою перевірки ефективності розробленого методу прунінгу було 
вирішено оптимізувати модель архітектури візуальних трансформерів для 
відео, оскільки вона ефективно аналізує просторові та часові залежності й 
вирішує задачу визначення зміни сцен. Моделі архітектури візуальних 
трансформерів для відео потребують високих обчислювальних ресурсів як під 
час виконання, так і в процесі навчання. Тому застосування розробленого 
методу прунінгу для їх оптимізації має забезпечити значне підвищення 
ефективності таких моделей. 
Під час навчання моделі архітектури візуального трансформера для 
відео з метою вирішення задачі розпізнавання зміни сцен було вирішено 
використовувати датасети Raid, OsVsd та BBC Planet Earth. Ці датасети було 
розділено на тренувальну та валідаційні вибірки, які містили 7 856 сцен 
загальною тривалістю 1 047 хвилин для тренування моделі та 4 844 сцени 
загальною тривалістю 539 хвилин для тестування результатів навчання 
розробленої моделі архітектури візуального трансформера для відео. З метою 
оптимізації навчання та підвищення точності моделі було вирішено 
покращити датасет шляхом додаткового визначення планів для кожного відео 
та створення спеціальної розмітки, яка містила інформацію про сцени, плани, 
що входять до кожної сцени, а також про сусідні сцени. Завдяки цій 
модифікації датасету стало можливим використання лише ключових кадрів 
для кожного плану та зміна порядку сцен і планів усередині сцени з метою 
штучного розширення датасету при збереженні оригінального контексту 
сцени. Також це дозволило під час розробки архітектури візуального 
122 
трансформера для відео значно зменшити довжину послідовності, яка 
надходила на вхід моделі, завдяки використанню лише ключових кадрів для 
кожного плану. Після навчання моделі архітектури візуального трансформера 
для відео було вирішено застосувати розроблений метод прунінгу з метою 
порівняння змін у точності та швидкодії моделі до та після його застосування. 
В результаті застосування розробленого методу прунінгу було 
встановлено, що розмір моделі зменшився на 43%, швидкодія моделі зросла 
на 10%, а її точність покращилася на 0,4%, що продемонстровано в таблиці 
3.1. 
Таблиця 3.1. Порівняння результатів виявлення зміни сцен 
Модель 
Розроблена модель 
F1 
Розроблена 
0.721 
модель 
після 
0.725 
застосування методу прунінгу 
Deep Multimodal Networks [3] 
STG[4] 
0.67 
0.41 
NW[5] 
0.33 
Однак важливо зауважити, що для тестування швидкодії 
використовувалася відеокарта NVIDIA RTX 3070, яка, хоча й має Tensor Cores, 
не підтримує роботу з розрідженими матрицями формату 2:4, що утворюються 
при застосуванні розробленого методу прунінгу. Зважаючи на особливості 
доступного для тестування апаратного забезпечення, не вдалося досягти 
максимального рівня пришвидшення. Проте при використанні моделі 
архітектури візуального трансформера після застосування розробленого 
методу прунінгу на спеціалізованому апаратному забезпеченні, такому як 
графічні процесори від NVIDIA з підтримкою обробки розріджених матриць 
формату 2:4, таких як A100, A30 чи H100, можливо досягти значного 
підвищення швидкодії моделі. 
123 
Отже, дослідження показало, що застосування розробленого методу 
прунінгу дозволяє значно зменшити розмір моделі, підвищити швидкість її 
виконання, і при цьому зберігається оригінальна точність. Це робить 
застосування розробленого методу ефективним у задачах оптимізації 
нейронних мереж на основі архітектури трансформерів, особливо при 
подальшому використанні оптимізованих моделей на спеціалізованому 
апаратному забезпеченні. 
3.3. Висновки до розділу 3 
В результаті проведених експериментів було встановлено, що 
розроблений метод прунінгу демонструє високу ефективність при оптимізації 
моделей архітектури візуальних трансформерів для відео завдяки значному 
зменшенню розрахункових витрат при збереженні точності моделі. При цьому 
було досліджено різні підходи до прунінгу глибоких нейронних мереж, що 
дозволили покращити найбільш важливі елементи прунінгу нейронних мереж 
на основі архітектури трансформерів з метою одночасного зменшення розміру 
моделі, підвищення швидкодії та збереження оригінальної точності. Першою 
частиною модифікованого методу прунінгу стало покращене визначення 
важливості ваг у методі SNIP за рахунок додавання розрахунку активацій 
уваги та векторів виходу моделі до загальної функції втрат. Другою частиною 
покращеного методу прунінгу стала інтеграція розрідженості матриць за 
шаблоном 2:4, що дозволяє працювати з напіврозрідженими матрицями. 
В результаті експериментів було встановлено, що при використанні 
апаратного забезпечення без підтримки роботи з розрідженими матрицями 
модель демонструє пришвидшення приблизно на 10%. При цьому моделі на 
основі архітектури трансформерів мають потенціал значного збільшення 
швидкодії при використанні спеціалізованого апаратного забезпечення, такого 
як NVIDIA A100, A30 чи H100. Також важливим аспектом покращеного 
124 
методу прунінгу є збереження оригінальної точності моделі, що робить цей 
метод надзвичайно ефективним для задач, у яких втрата точності може бути 
критичною. Крім того, застосування цього підходу дозволяє не лише 
пришвидшити використання моделі, а й значно прискорити процес її навчання. 
Проведене дослідження підтверджує ефективність запропонованого 
методу прунінгу при його застосуванні до моделей архітектури 
трансформерів. Метод забезпечує підвищення продуктивності, зменшення 
розміру моделі та збереження її оригінальної точності. Це дозволяє 
використовувати його для вирішення завдань, що потребують високої 
швидкодії, зокрема для аналізу відеоконтенту. 
125 
РОЗДІЛ 4. ПРОЄКТУВАННЯ ТА РОЗРОБЛЕННЯ 
ПРОГРАМНОГО ЗАБЕЗПЕЧЕННЯ ДЛЯ ВИЗНАЧЕННЯ 
ВІДЕОАТРИБУТІВ 
Для забезпечення виконання вимог до програмного забезпечення для 
автоматизованого визначення відеоатрибутів із використанням розбиття відео 
на сцени та плани, що були сформульовані у розділі 1, пропонується 
універсальна архітектура програмної системи, що зображена на рисунку 4.1. 
Компоненти цієї архітектури можна розділити на чотири групи: 
− модулі для обробки відео, взаємодії з розподіленими 
обчислювальними ресурсами, паралельного обчислення відеоатрибутів та 
керування потоком даних; 
− компоненти для прунінгу перед тренуванням, які дозволяють 
оптимізувати нейронні мережі шляхом усунення малозначущих параметрів, 
що знижує обчислювальні витрати та підвищує швидкодію моделі без значної 
втрати точності; 
− модулі для автоматизованого розбиття відео на плани та сцени, що 
використовують візуальні трансформери для точного виявлення змін у 
відеопотоках; 
− система збереження та аналізу отриманих результатів, яка дозволяє 
зберігати та обробляти метрики, отримані в процесі визначення зміни планів, 
сцен та відеоатрибутів. 
Основу архітектури становлять модулі для завантаження відео, 
підготовки до аналізу, визначення змін кадрів (планів) і керування 
розподіленими ресурсами для обробки відеоконтенту. Моделі, які 
використовуються для визначення змін сцен, планів та аналізу відеоатрибутів, 
зберігаються в окремому сховищі. Це забезпечує зручний доступ до них, а 
також можливість оновлення або додавання нових моделей для аналізу.
126 
Рисунок 4.1 – Універсальна архітектура програмної системи для розподіленого визначення відеоатрибутів 
127 
Під час аналізу відео кадри трансформуються та передаються до модуля 
визначення змін планів, який детально описано в розділі 4.4. Коли цей модуль 
виявляє зміну плану, він обирає ключові кадри. При цьому є можливість 
додаткового налаштування моделі для збільшення кількості ключових кадрів 
у плані, що дозволяє отримати більше даних для аналізу. Далі ці кадри разом 
із інформацією про план передаються до модулів, що зберігають даних перед 
аналізом для подальшого аналізу та керують обчислювальними потоками для 
обробки відео, а саме потоками для визначення сцен і атрибутів.  
Модулі для зберігання даних перед аналізом дозволяють ефективно 
обробляти інформацію та групувати її відповідно до вимог модулів аналізу. 
Для аналізу сцен розроблений модуль зберігання даних групує інформацію за 
групами та передає їх у вигляді наборів зображень, що необхідно для 
визначення плану. Це дає змогу ефективно аналізувати зміну планів на різних 
потоках, оскільки кожен потік отримує власну копію зображень, необхідних 
для аналізу. Для визначення атрибутів модуль зберігання даних перед аналізом 
дозволяє накопичувати інформацію та передавати її у вигляді наборів 
зображень, що забезпечує ефективне використання розподілених обчислень, 
закладених в архітектуру нейронних мереж. При цьому набір даних може бути 
налаштований залежно від характеристик апаратного забезпечення. 
Модулі для обчислювальними потоками мають доступ до відповідних 
баз даних, у яких зберігається інформація про потоки та результати їхньої 
роботи. Завдяки цьому система може приймати рішення про зміну кількості 
активних потоків, а також визначати, які потоки доступні для подальшої 
обробки інформації. Після завершення аналізу результати передаються до 
модуля збереження та візуалізації статистики. Користувач має можливість 
взаємодіяти з цим модулем, отримуючи деталізовану інформацію про 
оброблене відео, яка включає в себе точні часові мітки зміни планів та сцен, а 
також атрибутів які були визначені в процесі аналізу, як для кожної сцени та 
плану, так і узагальнені для всього відео. 
128 
Під час визначення атрибутів користувач може використовувати власні 
методи аналізу. Водночас архітектура підтримує автоматичне навчання 
моделей із використанням розробленого методу прунінгу перед навчанням, що 
детально описано в розділі 4.3. Для використання цього модуля користувачеві 
потрібно передати тренувальний набір та архітектуру нейронної мережі. У 
результаті система навчить оптимізовану модель, яка буде збережена у 
сховищі моделей для подальшого використання. 
Важливою особливістю розробленої архітектури є її здатність ефективно 
використовуватися в хмарному середовищі. Асинхронні задачі визначення 
сцен та атрибутів на відео можуть запускатися у вигляді контейнерів на 
віртуальних машинах, таких як AWS EC2, що дозволяє обирати оптимальні 
налаштування залежно від обсягу обчислень та їхньої складності. Крім того, 
це дає змогу використовувати спеціалізоване апаратне забезпечення, таке як 
NVIDIA A100, A30 чи H100, для ефективного виконання моделей, 
оптимізованих методом прунінгу у форматі 2:4. Для керування цими 
контейнерами можна застосовувати спеціалізовані хмарні технології, такі як 
Kubernetes. Зберігання даних можна реалізувати шляхом поєднання 
віртуальних машин чи асинхронних задач, таких як AWS Lambda та Azure 
Functions, із сховищами для зберігання даних, такими як Amazon DynamoDB. 
Розроблена архітектура забезпечує ефективний аналіз відеоконтенту з 
можливістю гнучкого керування обчислювальними ресурсами та автоматично 
адаптується до різного рівня навантаження, що особливо важливо при роботі 
з великими обсягами даних. При цьому архітектура створена з урахуванням 
можливості інтеграції із сучасними хмарними середовищами, такими як AWS, 
Azure та Google Cloud. Розроблена архітектура є гнучкою, адаптивною та може 
використовуватися як для аналізу великих обсягів даних, так і для обробки 
відео в реальному часі. 
129 
4.1. Засоби розроблення для програмного забезпечення визначення 
відеоатрибутів 
Середовищем розробки було обрано інтегроване середовище розробки 
(IDE) PyCharm, створене спеціально для розробки програмного забезпечення 
мовою програмування Python. PyCharm має вбудовану систему автоматичного 
доповнення коду, інструменти для швидкого та ефективного рефакторингу, а 
також засоби для налагодження коду. Крім того, середовище підтримує 
використання вбудованих інструментів для підвищення ефективності 
навчання та роботи з нейронними мережами, таких як Jupyter Notebook, 
NumPy та TensorFlow.  
Для збереження даних було вирішено використовувати нереляційну базу 
даних MongoDB, розроблену для роботи з великими обсягами 
неструктурованих або напівструктурованих даних. На відміну від реляційних 
баз 
даних, 
MongoDB використовує документо-орієнтовану модель 
збереження, що дозволяє гнучко змінювати схему даних. Це робить MongoDB 
ефективним рішенням для аналітики, особливо у системах керування 
контентом. Завдяки цьому можна швидко змінювати необхідні атрибути для 
побудови відеоаналітики, впроваджувати нові рішення та тестувати підходи. 
Крім того, MongoDB має оптимізовані механізми індексації та агрегації, що 
забезпечує ефективний пошук і швидку обробку даних [136].  
Для керування базою даних було вирішено використовувати DataGrip, 
оскільки цей інструмент дозволяє ефективно адмініструвати бази даних і 
підтримує велику кількість СУБД, включаючи MongoDB. DataGrip має 
вбудовану систему автодоповнення SQL-запитів, можливість візуалізації 
зв’язків між таблицями, інструменти для оптимізації SQL-запитів, а також 
вбудований редактор документів у форматі JSON, що є особливо корисним 
при роботі з MongoDB.  
Для 
130 
роботи з багатовимірними масивами було вирішено 
використовувати бібліотеку NumPy, яка пропонує широкий набір 
математичних функцій для роботи з матрицями. NumPy забезпечує високу 
швидкість виконання математичних операцій завдяки використанню 
оптимізованих бібліотек, написаних мовами програмування C та Fortran. Це 
робить цей інструмент надзвичайно корисним для аналізу даних, проведення 
наукових обчислень та підготовки даних для машинного навчання [137].  
Для роботи з зображеннями була обрана бібліотека OpenCV завдяки 
великій кількості оптимізованих операцій для аналізу та трансформації 
зображень. OpenCV містить реалізації класичних математичних методів, таких 
як виділення ключових точок, розпізнавання об'єктів, побудова гістограм, 
геометричні трансформації та визначення країв, що робить цю бібліотеку 
надзвичайно корисною для задач, пов'язаних із комп'ютерним зором. Крім 
того, OpenCV забезпечує високу швидкість обчислень, оскільки реалізована 
переважно мовою програмування C++ та використовує оптимізовані 
бібліотеки для прискорення обчислень, такі як Intel IPP, OpenCL та CUDA 
[138]. 
Для створення та збереження нейронних мереж було вирішено 
використовувати бібліотеки PyTorch і TensorFlow, залежно від типу 
створюваної нейронної мережі.  
4.2. Програмне забезпечення для реалізації та впровадження 
нейронних мереж 
Для реалізації нейронних мереж було вирішено використовувати 
бібліотеку TensorFlow, яка дозволяє ефективно навчати глибокі нейронні 
мережі та містить інструменти для масштабування їх використання й 
підготовки до застосування у промислових системах. Зокрема, TensorFlow має 
131 
вбудовані інструменти, такі як TensorFlow Serving для ефективного 
розгортання моделей і TensorFlow Lite для оптимізації моделей для 
використання на мобільних пристроях. Бібліотека TensorFlow використовує 
статичні графи для обчислень, що дозволяє підвищити продуктивність та 
ефективно виконувати операції на різних типах апаратного забезпечення. Для 
роботи з даними TensorFlow пропонує пакет tf.data, який містить функціонал 
для ефективного завантаження та обробки даних, що значно спрощує навчання 
моделей при роботі з великими обсягами інформації. Також у TensorFlow є 
спеціальне розширення для створення повноцінних конвеєрів машинного 
навчання, які автоматизують процеси від збору та обробки даних до 
розгортання моделі[136, 139].  
Проте під час дослідження можливостей моделей архітектури 
візуальних трансформерів для відео та оптимізації таких моделей було 
вирішено використати бібліотеку PyTorch, яка також є спеціалізованим 
інструментом для навчання глибоких нейронних мереж. Основною 
особливістю PyTorch є використання динамічного обчислювального графу, що 
забезпечує більшу гнучкість у розробці нейронних мереж, спрощує 
відлагодження моделей та дозволяє адаптивно змінювати архітектуру під час 
навчання. PyTorch також підтримує новітні технології для графічних 
процесорів, що робить його ефективним для роботи з великими нейронними 
мережами та обробки даних у реальному часі. Додатковою перевагою є 
наявність інструменту TorchScript, який дозволяє конвертувати моделі для 
ефективного розгортання на платформах з обмеженими ресурсами. Це значно 
розширює можливості використання PyTorch у мобільних і вбудованих 
системах, а також у хмарних обчисленнях [140].  
Ключовим компонентом бібліотеки PyTorch є torch.Tensor, який є 
основною структурою для представлення та обробки даних. Цей об’єкт 
дозволяє ефективно працювати з багатовимірними масивами, виконуючи 
операції як на графічному (GPU), так і на центральному процесорі (CPU). Крім 
132 
того, torch.Tensor має вбудовані функції для автоматичного диференціювання, 
що робить його надзвичайно корисним для навчання глибоких нейронних 
мереж. Бібліотека PyTorch також містить систему автоматичного обчислення 
градієнтів – torch.autograd, яка дозволяє легко застосовувати алгоритми 
оптимізації, використовуючи правило ланцюгової похідної. Це забезпечує 
ефективний процес зворотного поширення помилки (backpropagation) та 
значно спрощує реалізацію навчання моделей. Для створення архітектури 
нейронних мереж використовується пакет torch.nn який містить в собі готову 
реалізацію різних шарів, таких як torch.nn.Linear, для роботи з повноз’язними 
шарами, torch.nn.Conv2d, для використання згорткових шарів, чи torch.nn.RNN 
для рекурентних шарів. Під час створення шарів для них автоматично 
створюються відповідні параметри (вагові коефіцієнти), які оновлюються під 
час оптимізації моделі. Крім того, torch.nn містить механізми для 
автоматичного додавання функцій активації, таких як ReLU, Sigmoid чи 
Softmax, що дозволяє легко інтегрувати нелінійність у структуру нейронних 
мереж.  
Бібліотека TensorFlow має аналог torch.Tensor, який називається 
tf.Tensor. Він є основною структурою для представлення багатовимірних 
масивів і підтримує виконання операцій у розподіленому середовищі. 
Використання статичного графа обчислень у TensorFlow дозволяє 
оптимізувати частину розрахунків ще на етапі компіляції моделей, що значно 
покращує продуктивність під час роботи з великими нейронними мережами. 
Механізм автоматичного диференціювання, який дозволяє ефективно 
обчислювати градієнти під час навчання, у TensorFlow реалізований за 
допомогою класу tf.GradientTape. Він забезпечує автоматичне відстеження 
всіх операцій для подальшого обчислення градієнтів під час зворотного 
поширення помилки. Реалізація вже готових шарів для навчання знаходиться 
в пакеті tf.keras.layers, яка включає в себе такі шари як tf.keras.layers.Dense, 
tf.keras.layers.Conv2D та tf.keras.layers.LSTM. Шари можуть бути використані 
133 
для побудови моделі за допомогою класів tf.keras.Sequential, де вони  
додаються у цей клас у вигляді масиву, чи tf.keras.Model, який приймає як 
параметри входи і виходи моделі, а шари зв’язуються між собою 
функціональним стилем програмування.  
Основним алгоритмом для навчання нейронних мереж називається 
зворотнім поширенням помилки, та базується на оновлені вагів моделі 
нейронної мережі на основі функції втрат. Для обчислення градієнтів функції 
втрати щодо кожної ваги у кожному шарі моделі застосовується правило 
ланцюгової похідної. Обчислення градієнтів складається з двох етапів, а саме 
прямого та зворотного поширення. Під час прямого поширення вхідні дані 
проходять через всі шари нейронної мережі, де кожен нейрон виконує лінійне 
перетворення за наступною формулою:  
 
  =𝑊𝑥+𝑏
 та нелінійне активаційне перетворення 
 
  =𝜎(𝑧)
 (4.1) 
(4.2) 
де 𝑊 є матрицею вагів, 𝑏 — зміщення, проте важливо зауважити, що цей 
параметр можна не використовувати в деяких випадках, 𝑥 це матриця вхідного 
сигналу, а 𝜎(𝑧)  — функція активації яка забезпечую нелінійність перетворень, 
наприклад функції ReLU чи sigmoid.  В результаті роботи прямого поширення 
на шарах виходу утворюється результат аналізу вхідних даних за допомогою 
нейронної мережі, після чого отриманий результат порівнюється з очікуваним 
за допомогою функції втрати. Функція втрати залежить від задачі яку вирішує 
нейронна мережа, при цьому для деяких задач може підходити декілька 
функцій втрат. Найбільш розповсюдженою є функція втрати яка розраховує 
середньоквадратичну помилку: 
134 
 
  = 1
 𝑁
 𝑁
 ∑(
 𝑖=1
 𝑦𝑖 −𝑦̂𝑖)2
 (4.3) 
Наступним етапом є застосування зворотнього поширення, де за 
допомогою градієнтного спуску обчислюються часткові похідні функції втрат 
для кожного параметру моделі, використовуючи ланцьогове правило, яке 
можна представити за допомогою формули: 